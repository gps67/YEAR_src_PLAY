2020-05-04 May Mon 23:08 2020-05-04_PATTERNS_DECODER.txt

	PATTERNS_DECODER.txt

		WORD DECODER
		USES[u2]
		[0] EXPR // MATH wins, dont let there be something worse
		[1] ITEM // IDX or this [idx] as_ITEM
		[2] PLUS // TREE TWIG ITEM EXPR
		[3] LIST // STRUCT VECT TUPLO TREE POOL

		NOTE the PAYLOAD parameters used as per OPCODE SPEC

		// REQUIRE // SCOPE REQUIRES // you_must_call_SET( EXPR )
		// PROOF is to match each code path CONFIRM always_set
		// SCOPE is neat CTXT SESS ./STEP/.
		// { STEP } // ...

	WORD DECODERS

		u64_WORD_lohi
		u64_WORD_hilo
		u32_WORD_cpu
		u16_WORD_PART_cpu
	typedef
		u16_WORD_PART_cpu	// The best choice for Item_t
		u16_WORD_PART;		// EXPLAIN = SIMPLIFY essence
	typedef
		u16_WORD_PART_expr	// The best choice for Item_t
		u16_WORD_FIELD;		// EXPLAIN = get_u16( WORD, WORD_PART )
		// WORD_PART = bitfield b2[b0] // STRICT P0P2 MIRROR b2b0
		// because bits numbered right to left, bytes left to right
		// ACCESS_SCRIPT_S[u2]
		// SCOPE REQUIRES // u2 = u2_from_lookup( & TOKEN )
		// [0123] // REQUIRE name PROVIDE u2 + current SPELLING
		// REFACTORY // u2_next = next_from_prev

	FIRST BYTE tells us how many words or even N_BYTES

		u64 _as_ DECODED_u32_u16_u8_u8_lohi ; // STRANGE WIN
		u64 _as_ DECODED_u48_u8_u8_lohi ; // CACHE_DIRECT_PTR

		u64_as_f32_with_UNUSED_u16 // f32_i32 _lohi
		u64_as_f32_with_DECODE_u16 // f32_i32 _lohi
		u64_as_f32_with_OPTIONS_u16 // f32_i32 _lohi

		DECODE_u16_as_u8_A_u8_B // decode A FIRST maybe shift down B
		// INSITU no shift required for BYTE_B
		// CODE_PATH_FORK // CROSS_ROADS //
		// A == OPCODE B == PAYLOAD
		// u16_AB = u16[0]
		// u16_AB // u16[0]
		// u16_CD // u16[1]
		// u16_EF // u16[2]
		// u16_GH // u16[3]
		// u48_ABCDEF // 
		// u32_ABCD // in_cpu_looks_like_DCUBA // "de_cuba_four"
		// u32_ABCD // { FROM_u64_ABCD_EFGH, FROM ABCD[i]
		// u32_EFGH // from ALIASES_of_u32_i("u32[idx]") // PAYLOAD_FIELDS
		// u8_D // WORD >> 16 ; GET BYTE_A // other ROTATES available
		// u8_C // WORD >> 16 ; GET BYTE_B 
		// u8_B // WORD >> 16 ; GET BYTE_A // other ROTATES available
		// u8_A // WORD >> 16 ; GET BYTE_B 
		// EXPR u8 NB // 64 // FILTER REWRITE ROTATE SHIFT BYTE_B // u6
		// EXPR u6 BIT_POS B0 B1 B2 B2[B0] // P0P2 MIRROR
		// EXPR u6 BIT_POS B2 B1 B0 // P0P2 MIRROR
		// ZERO is obvious FULL idx_FULL == 256 == x0100
		// u8_u3 // WORD << WW-B2 ; WORD >> (WW-NB) >> 16 ; GET BYTE_A // TBS (yawn)


RUN SIMUL

 SINGLE_STEP_ANALYSE_CODE
  SET TEMP_val = TEMP_VAR_const = SCOPE. POOL_NAME = POOLS[idx_of_POOL]
  = VALUE
  # u64_is_u16_vector_u2
  # u128_is_u16_vector_u3
  = VAR = INIT ... NOW ... NEAR ...
  = EXPR { SCRIPT }
  = EXPR // ITEM in SCRIPT, TWIG_in_TREE
  = CALL ARGV //  FUNC == ARGV[0] = NAME_EXPR
  FRAME = SCOPE(SCRIPT,DATA)

  ITERATE SCRIPT over all [u2] // calc weights or structure is plenty
  PRELOAD CACHE // OK you can have LINT const EXPR // FILTER GUESS
  LEARN CALLER CODE PATHS over SHARED stepping stones // lit_layers
  FILTER bunch of optimisations 
  SELECT from WEIGHTED CODE PATHS
  GEN ROM
  PRE LOAD TABLES

 SINGLE_STEP_ANALYSE_CODE
  LAYOUT = u64_cpu_from_u64_ABCD_EFGH
  LAYOUT = u64_cpu_from_u64_ABCD_BYTES
  LAYOUT = u64_cpu_from_u64_HILO_MEM
  LAYOUT = u64_cpu_as("u16_lohi[u2_idx]");
  LAYOUT = u64_cpu_as("_lohi_ u16[u2_idx]");
  ASSOCIATE WITH "u8 u2_idx; // FITS in a BYTE"
  ASSOCIATE WITH "WORD u2_idx; // bitfield is now WORD"
  ASSOCIATE WITH "WORD u2_idx; // bitfield within WORD"

 

