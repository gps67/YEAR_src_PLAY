	2024-06-27

	2024_06_Jun
	2024-06-27_QEMU_REAL_THREAD_SHAPING.txt

	KVM
		/home/gps/YEAR/src_read/KVM/
		 linux-6.9.7/
			Documentation/
			virt/
			kvm/
			api.rst

		suggested by
		https://mjmwired.net/kernel/Documentation/kvm/api.txt
	
	ISO
		https://rescuezilla.com/download

		burn from WIN32 using
		https://etcher.balena.io/
	
	NFS
		https://linux-nfs.org/wiki/index.php/Main_Page
	
	ES6+
		https://exploringjs.com/js/downloads/exploring-js-screen-preview.pdf



	QEMU
		it does the work we monitor and request allocation quotas

		we as BUILTIN_CODE can use BURST_24_threads occasionally

		QUOTA BURST 24 Threads for 10 seconds # then 16 for 20
		QUOTA APPLY QUOTA_DONATION

			24 Threads for 10 seconds
			16 Threads for 20 seconds // x79 has 8 core 16 thread
			 8 Threads for 40 seconds
			 4 Threads for 90 seconds
			 2 Threads for 2 mins // 
			 1 Thread for 1 minute // standard UNIT of BILLING

			 That is active CPU, on SOLD TASK, not ASIDE

			 Reselling CPU to another SLOW_BATCH
			 Throttle done as X25_KPS _PP _DOS_BOX

		All of these cost the same when CPU BATCH is 100% SOLD

			In practice, we run 100% BATCH at 20%-101%
			But that does DRAG at PEAK_TIME RUSH_HOUR
			Becasue maybe 50%, reduced when LOW BPM

	REAL_THREAD

		12_core 24 thread for 10 seconds // every MINUTE
		10_core 16 thread for 10 seconds // every MINUTE // += 8 loose threads

		THREAD SCHEDULING is a affinity between the physical CPU CORE
		and the SESS.CACHE.

		basically the same thread will run over the same CODE pages
		basically the same thread will run over the same DATA pages
		basically the same thread will run over the same MMAP pages
		basically the same thread will run over the same FILE buffers

		so when we choose to resume a frozen thread,
		we hope to get it to run on the same CORE it came from.

		RTFM thread_knows_which_core_it_is_running_on_now [0[u8

			You can have more than u8_idx CORES, I dont

			AUTO_GROW expands u8_idx to i24_idx_as_MORE
			_as_MORE means i24 on behalf of i12_i12_lhs_rhs

		they get loaded from SSD to MMAP
		 
	SHAPING



 KNOW
 GLOW
 	KNOW UTF8_in_CSET_BYTE_latin1

		MATCH BYTE LIST matching UTF8 
		MATCH BYTE LIST matching UTF8 via extra LENS

 GLOW WHY
	CSET_BYTE
	BYTE_Latin1
 	UTF8 is a necessity, how can we smuggle it through ?

	nbytes is supposed to go through ASIS BYTE_for_BYTE
	So any analysis, is a second TREE of PSG all with XPOS // OFFS //

 KNOW HERE
 	HERE is XPOS in STDIN or FILTER_IN or STREAM = PICK _IN
	XPOS is i12_OFFS // i4_OPCODE_i12_DATA

	 /* NONAME makes AUTO_ALLOC easier */ {
	 i4_OPCODE /* NONAME */ { // KEEP INDEX[idx] = NONAME = i4_OPCODE
	 // ie SCRIPT[i4_OPCODE MINUS_ZERO_PLUS but use all 16 if careful
	 // which is about as many as we want, for the INNER CACHE EA_VARS
	 // u12_idx // implemented as L_M_x_N_R_idx_ _idx_of_CSR _idx_as_XPOS
	 // u12_idx // 4096 ITEMS in a PAGE // AND // in_a_POOL //
	 // i16_holding_i13 // COMPILER with reduce MACROS OVER MACROS
	 // COMPILE will be running it's own CACHE //
	 // we use that, in the code we GEN, for readability and meaning

	 BENCH is a VIEW over DIAG and CODE

	 	TOTAL complexity about 300 // using 4096 // then u31

		u31 is a FACT in i32
		_when_PLUS

		u32_is_still_DIRECT_

		_with_M_N
		_with_L_R
	
	 That can also be ZOOMED out to i64 via u48

	 	u48_is_a_FACT_in i64 // u48_PAYLOAD == u64_WORD >> 16

			u64_WORD is an ALIAS for CPU64_MEM64_WORD_64 _WORD

		LIBR provides u48 by providing i64 to hold it SIGN_EXTEND
		LIBR actually prefers i32 because more concentrated core
		LIBR suited for u31 u24 u16 u12 u8_in_i31
		LIBR likes MINUS_ZERO_PLUS

		LIBR uses API M_x_N // x is idx // x sometimes z or M1 //
		LIBR uses u4_OPCODE in u4_u12 
		LIBR uses i4_OPCODE in i4_u12 

			u12_i4
			i12_u4	register these BITFIELDS asif AVAR but CALL

			GET "BY_NAME" // "i4 = i4_PAYLOAD" // () AVR_is_CODE
			GET "BY_CODE" // "WORD&0x0F" // DATA fits in a BYTE
			GET "BY_DATA" // "WORD << 24 >> 24 // clear BITS over
			GET "BY_CALL" // "get_i4()"

 BENCH offers FAIL in DIALECTS

 	AVAR = get_u24_PAYLOAD(/* VOID */) // from the VOID is CTXT SESS STO

		To overuse the same CODE_POINT
		By passing NULL as RET_VAR

			on_NULL( 
	
	GENS RULES

		PSG must get it back to being LOADED and CHECKED
		PSG must discern DIALECT from FILTER over STREAM
		PSG builds a TREE of TEXT found each with an XPOS

		We want to reduce storage and reduce NOISE
		so "{ XPOS FILE OFFS }"  becomes "{ XPOS OFFS }"
		so "{ FILE = CURRENT_STREAM_FILE }" // expr returns expr

		repeat EVAL expr from CALL in 20 waves

			stop is sameval returned - presume that is signal
			save expr to eval to get VALUE
			save KNOW got ASIS from FILTER // save overcall

		when EVAL returns a VALUE that is not a CALL_BACK_ASIF

			stop subscription to future WAVES of CALL_and_CALL 

			spreadsheet and lazy_eval bring habits and code

				TREE of DOCS

				NODE_marked_as_needing_RECALC

					already MARKED - no propagate
					counting USAGE - tickle_CACHE_counters
					RECALC_SCRIPT - _know_lock_run_
					RECALC_in_PROGRESS - _know_lock_run_
					RECALC_DONE - _know_lock_run_

				TREE of DEPS

					CT_RT can do a tree walk
					and eval left to right
					as it descends into each leaf

	Called CODE is only supposed to add to CACHE

	CACHE can build a future CACHE_PREP_SCRIPT _PRE_LOAD_ASSIST

		LIST of "AVAR" to TOKENISE_SPELLING // ROM_REGISTER_AVAR //
		LIST of "EXPR" to TOKENISE PHRASES // CT_RT ARGV Parameters
		LIST of "ANON_FFFF" to TOKENISE DATA_USED_in_HEAP_TEXT
	
	CACHE calls SPEC_CODE_for_INIT_SCRIPTS

		LIST_of_STR0 = { CACHE_for_this_DATA_item_and_SSA }
		LIST_of_STR0_CACHE = {
			DECL AVAR("_CACHE") 
			_CACHE = LIST_of_STR0
			_CACHE = AVAR("CACHE") // above applies again and again
			// DIAG exports multiple MENTIONS
			// EACH enough to MAKE_NOUN //
			// SOME enough to REGEN_AVAR_MODULE // a_mini_world

			MMAP holds a surrounding nbytes // TBS WRAP_PENDING
			WRAP holds nbytes
			HEAP inside nbytes // DECODE_HEAP // MMAP_HEAP //

			CACHE and ROM share exact same SPELLING of BUFFER
			MMAP uses a lot of OFFS instead of ADDR
			SCRIPT uses a lot of u4_OPCODE_u12_ITEM
			SCRIPT uses a lot of u4_HEAP_u12_ITEM
			SCRIPT uses a lot of u16_OPCODE_u16_HEAP_u32_ITEM

				u16_OPCODE
				u16_HEAP
				u32_ITEM


			u8_u8_u16_u32
			u8_u8_u16_u32 BITFIELD u32_u16_u8_u8

				when BITFIELDS we DRAW the CPU_WORD
				and low bits are now on the right
				and low BYTES are now on the right

				This will always be correct provided
				you loaded the WORD from LOHI

	CPU_WORD needs to provides its best inline for each of these

				u32_PAYLOAD
				u16_PAYLOAD
				 u8_BYTE_B
				 u8_BYTE_A

				i32_PAYLOAD
				i16_PAYLOAD
				 i8_BYTE_B
				 i8_BYTE_A
	
	CT_RT may know that a particularly troublesome CPU

		has no concept of "BYTE_B"
		so always uses a BITFIELD_GETTER // 
		COMPILER sees a LIST of routes to getting BITFIELD ACCESS
		COMPILER might pick NEAREST_CACHED_COPY_OF_ORIGINAL_WORD

			WORD << nbits_above_BITFIELD
			WORD >> nbits_above_BITFIELD 
			WORD >> nbits_below_BITFIELD // SIGNED SHIFT // UNSIGNED

			RIGHT_SHIFT = (
			  nbits_above_BITFIELD 
			+ nbits_below_BITFIELD
			// KNOW += CODE_POINT comments near here in SCRIPT TEXT
			)

			// THEN CPU_WORD == BITFIELD_PAYLOAD //
			// SIGNED propagates - as always with RIGHT_SHIFTS
			// CPU might have C_FLAG as extra_sign_bit BORROW_DONE


				u16_OPCODE
				u16_HEAP
				u32_ITEM

			SCRIPT uses a lot of u16_OPCODE_u16_HEAP_u32_ITEM
		}


 BENCH offers ALIAS DIALECTS

			GET "BY_CALL" // "get_i4()"
	"get_i4()"
	"if !get_i4(AVAR) goto FAIL"
	"AVAR = get_i4() || goto FAIL" // || interpreted as EXCEPTION_BOOL

	bool get_i4( EA_i4_EXPR & BITFIELD_in_WORD ) // i4_PAYLOAD
	bool get_i4_PAYLOAD( int_PLUS & i4_PAYLOAD ) // i4_PAYLOAD
	
	AVAR is actually API_GETTER

		



		LIBR uses u4_OPCODE in u4_u12 
		LIBR uses i4_OPCODE in i4_u12 


	 }

 BENCH offers THREADS 

 	Each THREAD goes to a QUEUE of tasks and works through several
	Thread invokes CHILD_EXEC and confers own TREAD_QUOTA_to_IT
	Thread invokes CHILD_EXEC and confers MULTI_THREAD to it // -j4

	THREADS are WEB SERVICE threads
	BUNDLES are WEB_SERVICE that likes to have 4_CORE

		eg CORE - COMMS to and from remote
		eg CODE - BLOCKING thread but low CPU_USAGE for RET_VAL
	
	PROMISE
		fine grain DECL for COMPILER to know stuff
		main grain DECL for RUNTIME to batch up with internal LOCKS
	
 DOCS PROMISE

 	RSN


 QEMU QUOTA

 	WANT linux ability to state that a thread will ONLY run on CORE_14_15
	THEN create a hundred such threads, and let LINUX sort it out
	QEMU runs a LINUX with only 4 CORE, so that is similar

	Dont want to run multiple QEMU for each group of 4 CPU THREADS
	WANT qemu to group allocations, but that is hmmm


	QUOTA N_CORE_THREADS

		ALSO 14 out of 16 leaving 2 for SQL and NET and 

		MOVE THREAD between CORES // multi_thread_per_core_already in
		CLOSE THREAD on CORE // has to run to completion, loses COIN
		OPEN THREAD on CORE // has to run to completion, gains COIN


			24 Threads for 10 seconds
			16 Threads for 20 seconds // x79 has 8 core 16 thread
			 8 Threads for 40 seconds
			 4 Threads for 90 seconds
			 2 Threads for 2 mins // 
			 1 Thread for 1 minute // standard UNIT of BILLING

	QUOTA BURST shifted to a QUOTA LEVEL


			BATCH accepts 20/60 seconds are BUSY
			BATCH accepts 1/3 seconds are BUSY

			BATCH uses kernel to NICE processes
			BATCH uses kernel to UNFAIR SOME NICE processes
			BATCH uses kernel to SWITCH UNFAIR FOCUS
	
	CPU picks THREADS with affinity to CORE

		Each runtime thread has a CORE_id


